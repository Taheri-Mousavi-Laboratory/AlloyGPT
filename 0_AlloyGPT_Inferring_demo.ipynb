{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82770886-77f3-4ed6-a59e-ece4fcdc1385",
   "metadata": {},
   "source": [
    "# Inferring demo for AlloyGPT\n",
    "\n",
    "## Goal:\n",
    "> - [ ] Due to license restriction of Thermo-Calc, you will be asked for \"dataset_key\" to access the dataset and \"model_key\" to the trained model.\n",
    "> - [ ] General user needs have access to Thermo-Calc to build the dataset and train their model.\n",
    "\n",
    "## Ref:\n",
    "> - 1. \n",
    "\n",
    "#### Bo Ni, Feb 18, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f420ab-44ea-4ca2-a866-ef61650ef05d",
   "metadata": {},
   "source": [
    "## 1. Check the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "238740c4-bd4e-4ba9-aed4-e73363f601e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The VirEnv kernal in action:  AlloyGPT_env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/trace/group/tmousavi/bni2/1_JupyterGit/workspace/AlloyGPT_InternalTest_0/AlloyGPT_env/lib/python3.10/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we have in software: \n",
      " Torch version: 2.6.0+cu124\n",
      "Python:  3.10.16 (main, Dec 11 2024, 16:24:50) [GCC 11.2.0]\n",
      "What hardware the software see:\n",
      "cuda:0\n",
      "# of GPU 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, sys\n",
    "# print('Here is : \\n', os.popen('pwd').read())\n",
    "# print('What we get in hardware: \\n', os.popen('nvidia-smi').read())\n",
    "\n",
    "kernel_name = os.path.basename(sys.executable.replace(\"/bin/python\",\"\"))\n",
    "print (\"The VirEnv kernal in action: \", kernel_name)\n",
    "# #\n",
    "# # # make it work for both py and notebook\n",
    "# # try:\n",
    "# #     from jupyter_client import kernelspec\n",
    "# #     spec = kernelspec.get_kernel_spec(kernel_name)\n",
    "# #     print(\"Path to it: \", spec.resource_dir)\n",
    "# # except:\n",
    "# #     print (\"This suppose to be a .py run\")\n",
    "# # # /path/to/my/kernel\n",
    "\n",
    "import torch\n",
    "print(\"What we have in software: \\n Torch version:\", torch.__version__)\n",
    "print('Python: ', sys.version) # no switch case code\n",
    "#\n",
    "print('What hardware the software see:')\n",
    "device = torch.device(\n",
    "    \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "print(device)\n",
    "num_of_gpus = torch.cuda.device_count()\n",
    "print(\"# of GPU\", num_of_gpus)\n",
    "#\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8316feef-e46f-4a9f-a890-8996133baff5",
   "metadata": {},
   "source": [
    "## 2. Configurate the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d3ba39-977d-4e62-a2db-241e3b7e3e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debug\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fcf8f2c-ad95-4282-82d8-9c2de3853c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'AlloyGPT.TestPack' from '/trace/group/tmousavi/bni2/1_JupyterGit/workspace/AlloyGPT_InternalTest_0/AlloyGPT/TestPack.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import AlloyGPT.UtilityPack as UtilityPack\n",
    "importlib.reload(UtilityPack)\n",
    "#\n",
    "import AlloyGPT.DataPack as DataPack\n",
    "importlib.reload(DataPack)\n",
    "#\n",
    "import AlloyGPT.ModelPack as ModelPack\n",
    "importlib.reload(ModelPack)\n",
    "#\n",
    "import AlloyGPT.TrainPack as TrainPack\n",
    "importlib.reload(TrainPack)\n",
    "#\n",
    "import AlloyGPT.TestPack as TestPack\n",
    "importlib.reload(TestPack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25eaa87a-c0b5-4122-bf82-69156e244074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import pandas as pd\n",
    "# ++\n",
    "import numpy as np\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cec725c-2c02-44c4-af66-b6eda6a2b370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your key to the pretained model: \n",
      "\n",
      " ········\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "model_key = getpass.getpass(\n",
    "    prompt=\"Please enter your key to the pretained model: \\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0f30c20-6493-4154-9ab6-0cd8c29d72ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# Global control key setup: may into yaml file\n",
    "# ===============================================\n",
    "# control key to be shared everywhere\n",
    "#\n",
    "CKeys = {}\n",
    "CKeys['Working_Mode'] = 3 # 1 # 0 # 1 # 2\n",
    "# 0: prepare dataset: run only on single node\n",
    "# 1: training,\n",
    "# 2: testing\n",
    "# 3: testing remote one\n",
    "CKeys['test_mode_level'] = 2 # 1, 2\n",
    "# 1: on testset preparation\n",
    "# 2: 5.3 make plots\n",
    "\n",
    "# only for restart of training part\n",
    "CKeys['IF_FirstRun'] = 2 # 1 # 2\n",
    "CKeys['Resume_from_where'] = 'LAST'\n",
    "# 1: train for 1st run; 2: other training loop\n",
    "\n",
    "CKeys['Problem_ID'] = 6\n",
    "# 1: Transformer-based causal LM: GPT2\n",
    "# 2: Mamba-based causal LM\n",
    "# 3: T-based causal LM + HF dataset on AlloyLan\n",
    "# 4: selfmade S6\n",
    "# 5: BPE tokenizer + hf-S6\n",
    "# 6: BPE tokenizer + GPT2\n",
    "\n",
    "# where to pick up the checkpoint\n",
    "# CKeys['Resume_from_where'] = \"LAST\" # \"BEST\"\n",
    "# as we are testing models, here we use the BEST\n",
    "CKeys['Resume_from_where'] = \"BEST\"\n",
    "\n",
    "# On Debug\n",
    "# CKeys['Debug']=1\n",
    "CKeys['Debug']=0\n",
    "\n",
    "if CKeys['Debug'] == 1:\n",
    "    CKeys['Debug_Data'] = 1\n",
    "    CKeys['Debug_Model'] = 1\n",
    "    CKeys['Debug_Train'] = 1\n",
    "    CKeys['Debug_Test'] = 1\n",
    "    # for On cluster run\n",
    "    CKeys['if_slient_run']=0\n",
    "else:\n",
    "    CKeys['Debug_Data']=0\n",
    "    CKeys['Debug_Model']=0\n",
    "    CKeys['Debug_Train']=0\n",
    "    CKeys['Debug_Test']=0\n",
    "    # for On cluster run\n",
    "    CKeys['if_slient_run']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91abcdb0-52fa-43b7-9be4-9f566a2807d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check CKeys: \n",
      "\n",
      "Working_Mode: 3\n",
      "test_mode_level: 2\n",
      "IF_FirstRun: 2\n",
      "Resume_from_where: BEST\n",
      "Problem_ID: 6\n",
      "Debug: 0\n",
      "Debug_Data: 0\n",
      "Debug_Model: 0\n",
      "Debug_Train: 0\n",
      "Debug_Test: 0\n",
      "if_slient_run: 1\n"
     ]
    }
   ],
   "source": [
    "print (\"Check CKeys: \\n\")\n",
    "for this_key in CKeys.keys():\n",
    "    print (f\"{this_key}: {CKeys[this_key]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f816f-c428-4f69-9a33-1bc1c8bf06e3",
   "metadata": {},
   "source": [
    "## 3. download the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a683b5d0-9234-4fbe-a608-f03e4bab1ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "259ca43c-6aee-4bdd-9021-2edd15cff54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path already exits. Use Caution...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trained_model_dir='./resu'\n",
    "\n",
    "if os.path.exists(trained_model_dir):\n",
    "    print(f\"Path already exits. Use Caution...\")\n",
    "else:\n",
    "    print(f\"Download the pretrained model...\")\n",
    "    print(f\"Note, this only works if you have the access key.\")\n",
    "    #\n",
    "    snapshot_download(\n",
    "        repo_id=\"Bo-Ni/AlloyGPT\",\n",
    "        local_dir='./',\n",
    "        repo_type=\"model\",\n",
    "        token=model_key,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68b649a0-2132-461d-8924-e58272aff663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter key\n",
    "\n",
    "PKeys={}\n",
    "# \n",
    "PKeys['wk_path']='./resu/'\n",
    "# \n",
    "PKeys['pk_data_pack']=PKeys['wk_path']+'/data_pack.pickle'\n",
    "PKeys['pk_model_pack']=PKeys['wk_path']+'/model_pack.pickle'\n",
    "PKeys['pk_train_pack']=PKeys['wk_path']+'/train_pack.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129de2b6-e3a1-4371-a0e6-4e21b82e4c41",
   "metadata": {},
   "source": [
    "## 4. On dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a09a51a0-4798-4c32-9f76-95e0f11e1080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import (\n",
    "    load_dataset,\n",
    "    load_from_disk,\n",
    "    load_dataset_builder,\n",
    "    get_dataset_split_names,\n",
    "    DatasetDict,\n",
    ")\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eb0c033-6616-4f9f-8201-f6a231ee6f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "This is not a data-prepare run\n",
      "Load back in the data packages...\n",
      "==========================================\n",
      "./resu//data_pack.pickle\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# get from test mode\n",
    "# \n",
    "print(\"==========================================\")\n",
    "print ('This is not a data-prepare run')\n",
    "print ('Load back in the data packages...')\n",
    "print(\"==========================================\")\n",
    "\n",
    "\n",
    "print (PKeys['pk_data_pack'])\n",
    "with open(PKeys['pk_data_pack'], 'rb') as handle:\n",
    "    # data_pack = pickle.load(handle)\n",
    "    DataKeys = pickle.load(handle)\n",
    "\n",
    "# on tokenizer\n",
    "# ++\n",
    "tokenizer  = DataPack.reload_tokenizer(\n",
    "    DataKeys\n",
    ")\n",
    "\n",
    "# on dataloaders\n",
    "# train_dataloader = torch.load(DataKeys['data_dir']+'/train_dataloader.pt')\n",
    "# eval_dataloader = torch.load(DataKeys['data_dir']+'/eval_dataloader.pt')\n",
    "# test_dataloader = torch.load(DataKeys['data_dir']+'/test_dataloader.pt')\n",
    "# train_dataloader = torch.load(DataKeys['data_dir']+'/train_dataloader.pt',weights_only=False)\n",
    "# eval_dataloader = torch.load(DataKeys['data_dir']+'/eval_dataloader.pt',weights_only=False)\n",
    "# test_dataloader = torch.load(DataKeys['data_dir']+'/test_dataloader.pt',weights_only=False)\n",
    "\n",
    "\n",
    "# something else:\n",
    "sentence_dataset_dict_sepe = load_from_disk(\n",
    "    DataKeys['data_dir']+'/sentence_dataset_dict_hf'\n",
    ")\n",
    "\n",
    "print ('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f641a2-dff7-46bc-bde4-f00ea096ef77",
   "metadata": {},
   "source": [
    "## 5. on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bba94b62-5bc3-424c-973d-a5d34360c6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "This is not the first run\n",
      "Load back in the model packages...\n",
      "==========================================\n",
      "./resu//model_pack.pickle\n",
      "model_args: \n",
      " {'vocab_size': 256, 'n_layer': 36, 'block_size': 1024, 'n_embd': 1024, 'n_head': 16, 'bias': False, 'dropout': 0.2}\n"
     ]
    }
   ],
   "source": [
    "print(\"==========================================\")\n",
    "print ('This is not the first run')\n",
    "print ('Load back in the model packages...')\n",
    "print(\"==========================================\")\n",
    "print (PKeys['pk_model_pack'])\n",
    "\n",
    "with open(PKeys['pk_model_pack'], 'rb') as handle:\n",
    "    # data_pack = pickle.load(handle)\n",
    "    ModelKeys = pickle.load(handle)\n",
    "# \n",
    "# unpack the model_args key\n",
    "model_args = ModelKeys['model_args']\n",
    "print (\"model_args: \\n\", model_args)\n",
    "# \n",
    "# From Trainer to know what parameters to load in\n",
    "with open(PKeys['pk_train_pack'], 'rb') as handle:\n",
    "    # data_pack = pickle.load(handle)\n",
    "    TrainKeys = pickle.load(handle)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02159bb5-f899-40b8-8b4e-a73091f9a39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load from: Epoch 4, batch step 377600, accumulated updated step 47200\n",
      "Updated model_args:  {'vocab_size': 256, 'n_layer': 36, 'block_size': 1024, 'n_embd': 1024, 'n_head': 16, 'bias': False, 'dropout': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# if CKeys['Resume_from_where'] == 'LAST':\n",
    "#     ckpt_name = TrainKeys['out_dir_last']+'Last_ckpt.pt'\n",
    "#     # ++\n",
    "#     ckpt_info_txt = TrainKeys['out_dir_last']+'3_save_model_last.log'\n",
    "# elif CKeys['Resume_from_where'] == 'BEST':\n",
    "#     ckpt_name = TrainKeys['out_dir_best']+'Best_ckpt.pt'\n",
    "#     # ++\n",
    "#     ckpt_info_txt = TrainKeys['out_dir_best']+'3_save_model_best.log'\n",
    "\n",
    "# use the best checkpoint\n",
    "ckpt_name = TrainKeys['out_dir_best']+'Best_ckpt.pt'\n",
    "# ++\n",
    "ckpt_info_txt = TrainKeys['out_dir_best']+'3_save_model_best.log'\n",
    "    \n",
    "# \n",
    "# ++\n",
    "# get info from ckpt_info_txt\n",
    "ckpt_info_arr = np.loadtxt(ckpt_info_txt, delimiter=',', dtype=np.int32)\n",
    "print (f\"Load from: Epoch {ckpt_info_arr[0]}, batch step {ckpt_info_arr[1]}, accumulated updated step {ckpt_info_arr[2]}\")\n",
    "\n",
    "# \n",
    "# prepare to resume training from a checkpoint\n",
    "checkpoint = torch.load(ckpt_name, map_location=TrainKeys['device'])\n",
    "checkpoint_model_args = checkpoint['model_args']\n",
    "# \n",
    "# force these config attributes to be equal otherwise we can't even resume training\n",
    "# the rest of the attributes (e.g. dropout) can stay as desired from command line\n",
    "# \n",
    "# For new models, this is just a check\n",
    "# |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "# problem-specified\n",
    "for k in checkpoint_model_args.keys():\n",
    "    if model_args[k] != checkpoint_model_args[k]:\n",
    "        print (\"hard update needed on \", k)\n",
    "        print (\"old: \", model_args[k])\n",
    "        print (\"new: \", checkpoint_model_args[k])\n",
    "        model_args[k] = checkpoint_model_args[k]\n",
    "print (\"Updated model_args: \", model_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a829ef17-a6db-49d6-a45b-6886d70a6a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "Initialize the model from the scratch...\n",
      "=========================================\n",
      "number of parameters: 453.32M\n"
     ]
    }
   ],
   "source": [
    "print (\"=========================================\")\n",
    "print (\"Initialize the model from the scratch...\")\n",
    "print (\"=========================================\")\n",
    "#\n",
    "model_config = ModelPack.build_model_config(\n",
    "    CKeys,\n",
    "    model_args\n",
    ")\n",
    "# \n",
    "model = ModelPack.build_model(\n",
    "    CKeys,\n",
    "    model_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db630dc0-8742-4a20-89bc-55dfd2aa82a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe6c6f24-d83e-4090-930b-f4dea188cef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "Load back the model if this's not the 1st training.\n",
      "===================================================\n",
      "Loading the saved model...\n",
      "Load in the model...\n",
      "Update some other recrods...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print (\"===================================================\")\n",
    "print (\"Load back the model if this's not the 1st training.\")\n",
    "print (\"===================================================\")\n",
    "# \n",
    "# Here, for GPT, we use checkpoint to load back the model\n",
    "print (\"Loading the saved model...\")\n",
    "# \n",
    "state_dict = checkpoint['model']\n",
    "# NOTE, this one has unwanted contents.\n",
    "# fix the keys of the state dictionary :(\n",
    "# honestly no idea how checkpoints sometimes get this prefix, have to debug more\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "# \n",
    "# load back the previous breaking point\n",
    "print (\"Load in the model...\")\n",
    "model.load_state_dict(state_dict)\n",
    "print (\"Update some other recrods...\")\n",
    "\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42facc8a-c321-41c1-8b31-79570585e652",
   "metadata": {},
   "source": [
    "## 6. on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3508a3e3-b53d-40cf-845c-fa1898ccaa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c19a4525-d693-41da-b7c8-02b19507eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestKeys = {\n",
    "    'out_dir': PKeys['wk_path']+'/1_model/test_dir/',\n",
    "    'num_samples': 2,\n",
    "    'max_new_tokens': 1024,\n",
    "    'temperature': 0.8,\n",
    "    'top_k': 200,\n",
    "    'seed': 1337,\n",
    "    # 'device': 'cuda',\n",
    "    'dtype': 'bfloat16',\n",
    "    'compile': True\n",
    "}\n",
    "\n",
    "# for docker implementation\n",
    "if torch.cuda.is_available():\n",
    "    # \n",
    "    TestKeys['device']='cuda' # if device=='cuda:0' else 'cpu'\n",
    "else:\n",
    "    # \n",
    "    TestKeys['device']='cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d09e73c-fbf4-48e7-bdb9-3152ff07b933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given path already exists!\n",
      "The given path already exists!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestKeys['demo_dir'] = \\\n",
    "TestKeys['out_dir']+'demo_playground/'\n",
    "\n",
    "# create the folder\n",
    "UtilityPack.create_path(TestKeys['out_dir'])\n",
    "UtilityPack.create_path(TestKeys['demo_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2750884-0e93-4817-bcc4-1f545025596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestKeys, ctx = \\\n",
    "TrainPack.initialize_test_fun(TestKeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb71ba50-77ad-4cf6-aac3-11e8c53e6325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "On generation...\n",
      "==========================================\n",
      "Model structure:\n",
      "OptimizedModule(\n",
      "  (_orig_mod): GPT(\n",
      "    (transformer): ModuleDict(\n",
      "      (wte): Embedding(256, 1024)\n",
      "      (wpe): Embedding(1024, 1024)\n",
      "      (drop): Dropout(p=0.2, inplace=False)\n",
      "      (h): ModuleList(\n",
      "        (0-35): 36 x MHA_Block(\n",
      "          (ln_1): LayerNorm()\n",
      "          (attn): CausalSelfAttention(\n",
      "            (c_attn): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "            (c_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (attn_dropout): Dropout(p=0.2, inplace=False)\n",
      "            (resid_dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (ln_2): LayerNorm()\n",
      "          (mlp): MLP(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "            (gelu): GELU(approximate='none')\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (ln_f): LayerNorm()\n",
      "    )\n",
      "    (lm_head): Linear(in_features=1024, out_features=256, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/trace/group/tmousavi/bni2/1_JupyterGit/workspace/AlloyGPT_InternalTest_0/AlloyGPT_env/lib/python3.10/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print (\"==========================================\")\n",
    "print (\"On generation...\")\n",
    "print (\"==========================================\")\n",
    "model.eval()\n",
    "model.to(TestKeys['device'])\n",
    "if TestKeys['compile']:\n",
    "    model = torch.compile(model) # requires PyTorch 2.0 (optional)\n",
    "\n",
    "    print (f\"Model structure:\")\n",
    "    print (model)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24b5d4f-95a3-4346-90eb-d93ca9415c7e",
   "metadata": {},
   "source": [
    "### 6.1 on individual test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "447bc02b-d8ba-4b62-b103-6ad2f412f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "123e4922-c822-4aac-9ec6-6d242ca05f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "df_key_list = [\n",
    "    '(Al)', '(Ni)', '(Er)', '(Zr)', '(Y)', '(Yb)', \n",
    "    'AsBuilt_L12Mol%', 'AsBuilt_TernaryMol%',\n",
    "    'AsBuilt_Al3NiMol%', 'AsBuilt_Al3ZrMol%',\n",
    "    'L12Mol%', 'TernaryMol%','Al3NiMol%','Al3ZrMol%',\n",
    "    'DiffusionResistivity', 'Misfit', 'CoarseningMetric', \n",
    "    'FreezingRange','CrackSusceptibilityCoefficient','HotCrackingSusceptibility',\n",
    "]\n",
    "# \n",
    "Forward_CtoSP_Keys = [\n",
    "    # structure\n",
    "    'AsBuilt_L12Mol%', \n",
    "    'AsBuilt_TernaryMol%', \n",
    "    'AsBuilt_Al3NiMol%', \n",
    "    'AsBuilt_Al3ZrMol%', \n",
    "    'L12Mol%', \n",
    "    'TernaryMol%', \n",
    "    'Al3NiMol%', \n",
    "    'Al3ZrMol%', \n",
    "    # properties\n",
    "    'DiffusionResistivity', \n",
    "    'Misfit', \n",
    "    'CoarseningMetric', \n",
    "    'FreezingRange', \n",
    "    'CrackSusceptibilityCoefficient', \n",
    "    'HotCrackingSusceptibility',\n",
    "]\n",
    "# \n",
    "Forward_CStoP_Keys = [\n",
    "    # properties\n",
    "    'DiffusionResistivity', \n",
    "    'Misfit', \n",
    "    'CoarseningMetric', \n",
    "    'FreezingRange', \n",
    "    'CrackSusceptibilityCoefficient', \n",
    "    'HotCrackingSusceptibility',\n",
    "]\n",
    "# \n",
    "Inverse_PtoSC_Keys = [\n",
    "    # structure\n",
    "    'AsBuilt_L12Mol%', \n",
    "    'AsBuilt_TernaryMol%', \n",
    "    'AsBuilt_Al3NiMol%', \n",
    "    'AsBuilt_Al3ZrMol%', \n",
    "    'L12Mol%', \n",
    "    'TernaryMol%', \n",
    "    'Al3NiMol%', \n",
    "    'Al3ZrMol%',\n",
    "    # Composition:[\n",
    "    '(Al)', \n",
    "    '(Ni)', \n",
    "    '(Er)', \n",
    "    '(Zr)', \n",
    "    '(Y)', \n",
    "    '(Yb)',\n",
    "]\n",
    "# \n",
    "Inverse_PStoC_Keys = [\n",
    "    # Composition:[\n",
    "    '(Al)',\n",
    "    '(Ni)',\n",
    "    '(Er)',\n",
    "    '(Zr)',\n",
    "    '(Y)',\n",
    "    '(Yb)',\n",
    "]\n",
    "\n",
    "# add some keys to be used at the test set\n",
    "# 492 # 206 # 422 # 139\n",
    "input_len_for_tasks = {}\n",
    "input_len_for_tasks['CtoSP']=139 # 139\n",
    "input_len_for_tasks['CStoP']=353 # 422\n",
    "input_len_for_tasks['PtoSC']=223 # 206\n",
    "input_len_for_tasks['PStoC']=440 # 492\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e99d3a9-42a0-4103-bc52-02d34bae4f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def get_record_from_test_set(\n",
    "    i_record,\n",
    "    task_type,\n",
    "    sentence_set_name='test', # default as 'test', can be 'train'\n",
    "):\n",
    "    full_record = None\n",
    "    input_promp = None\n",
    "    error_msg = None\n",
    "    # \n",
    "    if task_type=='CtoSP' or task_type=='CStoP':\n",
    "        sentence_set_name = 'Pred001_sentence'\n",
    "    elif task_type=='PtoSC' or task_type=='PStoC':\n",
    "        sentence_set_name = 'Gene001_sentence'\n",
    "    else:\n",
    "        error_msg = \"Task type doesn't exists!\"\n",
    "        \n",
    "        \n",
    "    full_record = sentence_dataset_dict_sepe['test'][sentence_set_name][i_record]\n",
    "    input_promp = full_record[:input_len_for_tasks[task_type]]\n",
    "    \n",
    "    return full_record, input_promp, error_msg\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "# helper wrapping functions\n",
    "# \n",
    "def pick_one_and_prepare_promps_Prediction(ii):\n",
    "    \n",
    "    full_rec = sentence_dataset_dict_sepe['test']['Pred001_sentence'][ii]\n",
    "    CtoSP_pro = full_rec[:input_len_for_tasks['CtoSP']]\n",
    "    CStoP_pro = full_rec[:input_len_for_tasks['CStoP']]\n",
    "    \n",
    "    return full_rec, CtoSP_pro, CStoP_pro\n",
    "# \n",
    "def pred_CtoSP_and_CStoP_for_one_rec(\n",
    "    CtoSP_pro,\n",
    "    CStoP_pro,\n",
    "):\n",
    "    CtoSP_out = TrainPack.generate_single_example_AR_LM_w_token_tokenizer(\n",
    "        ctx,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        CtoSP_pro,\n",
    "        device=device,\n",
    "        pred_num=1,\n",
    "        max_new_tokens=536-len(CtoSP_pro), # 1024-len(input_prompt),\n",
    "        pred_temp=1.,\n",
    "        top_k=100,\n",
    "    )\n",
    "    \n",
    "    CStoP_out = TrainPack.generate_single_example_AR_LM_w_token_tokenizer(\n",
    "        ctx,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        CStoP_pro,\n",
    "        device=device,\n",
    "        pred_num=1,\n",
    "        max_new_tokens=536-len(CStoP_pro), # 1024-len(input_prompt),\n",
    "        pred_temp=1.,\n",
    "        top_k=100,\n",
    "    )\n",
    "    \n",
    "    return CtoSP_out[0], CStoP_out[0]\n",
    "# \n",
    "def convert_dict_str_to_val(dic):\n",
    "    dict_1 = dic.copy()\n",
    "    for this_key in dict_1.keys():\n",
    "        if this_key!='Task':\n",
    "            dict_1[this_key] = float(dict_1[this_key])\n",
    "    return dict_1\n",
    "\n",
    "def plot_compare_bar_plots(\n",
    "    sslabels,\n",
    "    value_list_1,\n",
    "    value_list_2,\n",
    "    label_1,\n",
    "    label_2,\n",
    "    y_label,\n",
    "    file_name,\n",
    "    # \n",
    "    legend_loc='best'\n",
    "):\n",
    "    \n",
    "    # sslabels = Forward_Short_Resu_Keys\n",
    "\n",
    "    x=np.linspace (0, len(sslabels)-1, len(sslabels))\n",
    "\n",
    "    # fig, ax = plt.subplots(1, 1)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6,4))\n",
    "\n",
    "    ax.bar(x-0.15, value_list_1, width=0.3, color='b', align='center')\n",
    "    ax.bar(x+0.15, value_list_2, width=0.3, color='r', align='center')\n",
    "\n",
    "    # ax.set_ylim([0, 1])\n",
    "\n",
    "    plt.xticks(range(len(sslabels)), sslabels, size='medium', rotation=90)\n",
    "    plt.legend ([label_1, label_2], loc=legend_loc)\n",
    "\n",
    "    plt.ylabel (y_label)\n",
    "    plt.savefig(file_name, bbox_inches='tight',dpi=100)\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    return file_name\n",
    "    \n",
    "def ana_CtoSP_vs_CStoP(\n",
    "    gt,\n",
    "    CtoSP_out,\n",
    "    CStoP_out,\n",
    "):\n",
    "    full_key_list = df_key_list+['SafeRec']\n",
    "    # \n",
    "    gt_dict = TestPack.covert_one_line_head_and_body(\n",
    "        gt,\n",
    "        df_key_list+['SafeRec']\n",
    "    )\n",
    "    gt_dict = convert_dict_str_to_val(gt_dict)\n",
    "    # \n",
    "    CtoSP_dict = TestPack.covert_one_line_head_and_body(\n",
    "        CtoSP_out,\n",
    "        df_key_list+['SafeRec']\n",
    "    )\n",
    "    CStoP_dict = TestPack.covert_one_line_head_and_body(\n",
    "        CStoP_out,\n",
    "        df_key_list+['SafeRec']\n",
    "    )\n",
    "    assert CtoSP_dict['SafeRec']=='1', 'Unreadable records'\n",
    "    assert CStoP_dict['SafeRec']=='1', 'Unreadable records'\n",
    "    \n",
    "    CtoSP_dict = convert_dict_str_to_val(CtoSP_dict)\n",
    "    CStoP_dict = convert_dict_str_to_val(CStoP_dict)\n",
    "    \n",
    "    # L1 error\n",
    "    L1_error_list = np.zeros((2, len(Forward_CtoSP_Keys)))\n",
    "    # for CtoSP\n",
    "    for ii, this_key in enumerate(Forward_CtoSP_Keys):\n",
    "        L1_error_list[0,ii] = np.fabs(CtoSP_dict[this_key]-gt_dict[this_key])\n",
    "    # for CStoP\n",
    "    for ii, this_key in enumerate(Forward_CtoSP_Keys):\n",
    "        if this_key in Forward_CStoP_Keys:\n",
    "            L1_error_list[1,ii]=np.fabs(CStoP_dict[this_key]-gt_dict[this_key])\n",
    "    \n",
    "    # drow \n",
    "    \n",
    "    \n",
    "    \n",
    "    return L1_error_list\n",
    "# \n",
    "def plot_CtoSP_CStoP(\n",
    "    gt,\n",
    "    CtoSP_out,\n",
    "    CStoP_out,\n",
    "    file_name=TestKeys['demo_dir']+'/L1_CtoSP_CStoP.png'\n",
    "):\n",
    "    L1_error_list=ana_CtoSP_vs_CStoP(\n",
    "        gt,\n",
    "        CtoSP_out,\n",
    "        CStoP_out,\n",
    "    )\n",
    "\n",
    "    plot_compare_bar_plots(\n",
    "        sslabels=Forward_CtoSP_Keys,\n",
    "        value_list_1=L1_error_list[0,:],\n",
    "        value_list_2=L1_error_list[1,:],\n",
    "        label_1='CtoSP',\n",
    "        label_2='CStoP',\n",
    "        y_label='L1 error',\n",
    "        file_name=file_name\n",
    "    )\n",
    "    return file_name\n",
    "\n",
    "# for Tab C\n",
    "# =======================================================\n",
    "def pick_one_and_prepare_promps_Design_PtoSC(ii):\n",
    "    \n",
    "    full_rec = sentence_dataset_dict_sepe['test']['Gene001_sentence'][ii]\n",
    "    PtoSC_pro = full_rec[:input_len_for_tasks['PtoSC']]\n",
    "    PStoC_pro = full_rec[:input_len_for_tasks['PStoC']]\n",
    "    \n",
    "    return full_rec, PtoSC_pro # , CStoP_pro\n",
    "# \n",
    "\n",
    "def pred_PtoSC_for_one_rec_twice(\n",
    "    PtoSC_pro,\n",
    "    pred_t,\n",
    "):\n",
    "    PtoSC_out = TrainPack.generate_single_example_AR_LM_w_token_tokenizer(\n",
    "        ctx,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        PtoSC_pro,\n",
    "        device=device,\n",
    "        pred_num=2,\n",
    "        max_new_tokens=536-len(PtoSC_pro), # 1024-len(input_prompt),\n",
    "        pred_temp=pred_t,\n",
    "        top_k=100,\n",
    "    )\n",
    "    \n",
    "    return PtoSC_out[0], PtoSC_out[1]\n",
    "\n",
    "# =================================================================\n",
    "# \n",
    "def plot_three_bar_plots(\n",
    "    sslabels,\n",
    "    value_list_1, # gt\n",
    "    value_list_2,\n",
    "    value_list_3,\n",
    "    label_1,\n",
    "    label_2,\n",
    "    label_3,\n",
    "    y_label,\n",
    "    file_name,\n",
    "    # \n",
    "    legend_loc='best'\n",
    "):\n",
    "    \n",
    "    # sslabels = Forward_Short_Resu_Keys\n",
    "\n",
    "    x=np.linspace (0, len(sslabels)-1, len(sslabels))\n",
    "\n",
    "    # fig, ax = plt.subplots(1, 1)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6,4))\n",
    "\n",
    "    dX = 0.15\n",
    "    ax.bar(x-dX*2, value_list_1, width=2*dX, color='r', align='center')\n",
    "    ax.bar(x,      value_list_2, width=2*dX, color='b', align='center')\n",
    "    ax.bar(x+dX*2, value_list_3, width=2*dX, color='g', align='center')\n",
    "\n",
    "    # ax.set_ylim([0, 1])\n",
    "\n",
    "    plt.xticks(range(len(sslabels)), sslabels, size='medium', rotation=90)\n",
    "    plt.legend ([label_1, label_2, label_3], loc=legend_loc)\n",
    "\n",
    "    plt.ylabel (y_label)\n",
    "    plt.savefig(file_name, bbox_inches='tight',dpi=100)\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    return file_name\n",
    "    \n",
    "def get_vals_for_keys_in_dict(\n",
    "    this_dict,\n",
    "    key_list,\n",
    "):\n",
    "    val_list = []\n",
    "    for this_key in key_list:\n",
    "        val_list.append(this_dict[this_key])\n",
    "    return val_list\n",
    "    \n",
    "def plot_comp_for_PtoSC_1_2_and_FR(\n",
    "    gt,\n",
    "    PtoSC_out_1,\n",
    "    PtoSC_out_2,\n",
    "    # \n",
    "    file_name=TestKeys['demo_dir']+'/Comp_PtoSC_1_2_FR.png'\n",
    "):\n",
    "    full_key_list = df_key_list+['SafeRec']\n",
    "    # \n",
    "    gt_dict = TestPack.covert_one_line_head_and_body(\n",
    "        gt,\n",
    "        df_key_list+['SafeRec']\n",
    "    )\n",
    "    gt_dict = convert_dict_str_to_val(gt_dict)\n",
    "    # \n",
    "    \n",
    "    PtoSC_dict_1 = TestPack.covert_one_line_head_and_body(\n",
    "        PtoSC_out_1,\n",
    "        df_key_list+['SafeRec']\n",
    "    )\n",
    "    PtoSC_dict_2 = TestPack.covert_one_line_head_and_body(\n",
    "        PtoSC_out_2,\n",
    "        df_key_list+['SafeRec']\n",
    "    )\n",
    "    assert PtoSC_dict_1['SafeRec']=='1', 'Unreadable records'\n",
    "    assert PtoSC_dict_2['SafeRec']=='1', 'Unreadable records'\n",
    "    \n",
    "    PtoSC_dict_1 = convert_dict_str_to_val(PtoSC_dict_1)\n",
    "    PtoSC_dict_2 = convert_dict_str_to_val(PtoSC_dict_2)\n",
    "\n",
    "    plot_keys = ['(Ni)', '(Er)', '(Zr)', '(Y)', '(Yb)']\n",
    "\n",
    "    val_list_1 = get_vals_for_keys_in_dict(\n",
    "        this_dict=gt_dict,\n",
    "        key_list=plot_keys,\n",
    "    )\n",
    "    val_list_2 = get_vals_for_keys_in_dict(\n",
    "        this_dict=PtoSC_dict_1,\n",
    "        key_list=plot_keys,\n",
    "    )\n",
    "    val_list_3 = get_vals_for_keys_in_dict(\n",
    "        this_dict=PtoSC_dict_2,\n",
    "        key_list=plot_keys,\n",
    "    )\n",
    "\n",
    "\n",
    "    # make the plot\n",
    "    plot_three_bar_plots(\n",
    "        sslabels=plot_keys,\n",
    "        value_list_1=val_list_1, # gt\n",
    "        value_list_2=val_list_2,\n",
    "        value_list_3=val_list_3,\n",
    "        label_1='Known case',\n",
    "        label_2='Design 1',\n",
    "        label_3='Design 2',\n",
    "        y_label='Mol%',\n",
    "        file_name=file_name,\n",
    "        # \n",
    "        legend_loc='best'\n",
    "    )\n",
    "\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b12c14b7-581f-4588-98b0-66486c6945c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe9ef83-3531-423d-a71f-f809e58d0722",
   "metadata": {},
   "source": [
    "### Forward prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65eed788-cf4e-4e0e-a4af-09908afa396a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this demo, we focus on forward prediction and compare CtoSP and CStoP...\n",
      "\n",
      "Pick 11th record from the test set...\n",
      "\n",
      "The input prompt for CtoSP is \n",
      "\u001b[34m{Task:Pred001}={Composition:[(Al):+9.595e+01,(Ni):+6.830e-01,(Er):+1.874e+00,(Zr):+6.268e-01,(Y):+2.451e-02,(Yb):+8.439e-01]}=>{Structure:[\u001b[0m\n",
      "\n",
      "The input prompt for CStoP is \n",
      "\u001b[34m{Task:Pred001}={Composition:[(Al):+9.595e+01,(Ni):+6.830e-01,(Er):+1.874e+00,(Zr):+6.268e-01,(Y):+2.451e-02,(Yb):+8.439e-01]}=>{Structure:[AsBuilt_L12Mol%:+1.335e+01,AsBuilt_TernaryMol%:+2.546e-01,AsBuilt_Al3NiMol%:+2.266e+00,AsBuilt_Al3ZrMol%:+0.000e+00,L12Mol%:+1.348e+01,TernaryMol%:+0.000e+00,Al3NiMol%:+2.722e+00,Al3ZrMol%:+0.000e+00]}=>{Property:[\u001b[0m\n",
      "\n",
      "CtoSP prediction:\n",
      "\n",
      "\u001b[34m{Task:Pred001}={Composition:[(Al):+9.595e+01,(Ni):+6.830e-01,(Er):+1.874e+00,(Zr):+6.268e-01,(Y):+2.451e-02,(Yb):+8.439e-01]}=>{Structure:[\u001b[0m\u001b[31mAsBuilt_L12Mol%:+1.277e+01,AsBuilt_TernaryMol%:+5.124e-01,AsBuilt_Al3NiMol%:+1.867e+00,AsBuilt_Al3ZrMol%:+0.000e+00,L12Mol%:+1.321e+01,TernaryMol%:+0.000e+00,Al3NiMol%:+2.722e+00,Al3ZrMol%:+0.000e+00]}=>{Property:[DiffusionResistivity:+3.584e-01,Misfit:+1.132e+00,CoarseningMetric:+3.175e+00,FreezingRange:+1.451e+00,CrackSusceptibilityCoefficient:+2.004e-01,HotCrackingSusceptibility:+2.928e-01]}\u001b[0m\n",
      "\n",
      "CStoP prediction:\n",
      "\n",
      "\u001b[34m{Task:Pred001}={Composition:[(Al):+9.595e+01,(Ni):+6.830e-01,(Er):+1.874e+00,(Zr):+6.268e-01,(Y):+2.451e-02,(Yb):+8.439e-01]}=>{Structure:[AsBuilt_L12Mol%:+1.335e+01,AsBuilt_TernaryMol%:+2.546e-01,AsBuilt_Al3NiMol%:+2.266e+00,AsBuilt_Al3ZrMol%:+0.000e+00,L12Mol%:+1.348e+01,TernaryMol%:+0.000e+00,Al3NiMol%:+2.722e+00,Al3ZrMol%:+0.000e+00]}=>{Property:[\u001b[0m\u001b[31mDiffusionResistivity:+3.630e-01,Misfit:+1.127e+00,CoarseningMetric:+3.100e+00,FreezingRange:+1.181e+00,CrackSusceptibilityCoefficient:+1.998e-01,HotCrackingSusceptibility:+2.347e-01]}\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (f\"In this demo, we focus on forward prediction and compare CtoSP and CStoP...\\n\")\n",
    "\n",
    "i_pick = 11\n",
    "print (f\"Pick {i_pick}th record from the test set...\\n\")\n",
    "\n",
    "# t_full_rec, t_CtoSP_pro, t_CStoP_pro= \\\n",
    "# pick_one_and_prepare_promps_Prediction(\n",
    "#    ii=i_pick,\n",
    "# )\n",
    "t_full_rec = sentence_dataset_dict_sepe['test']['Pred001_sentence'][i_pick]\n",
    "t_CtoSP_pro = t_full_rec[:input_len_for_tasks['CtoSP']]\n",
    "t_CStoP_pro = t_full_rec[:input_len_for_tasks['CStoP']]\n",
    "\n",
    "print (f\"The input prompt for CtoSP is \\n{colored(t_CtoSP_pro, 'blue')}\\n\")\n",
    "print (f\"The input prompt for CStoP is \\n{colored(t_CStoP_pro, 'blue')}\\n\")\n",
    "\n",
    "t_CtoSP_out, t_CStoP_out = \\\n",
    "pred_CtoSP_and_CStoP_for_one_rec(\n",
    "    t_CtoSP_pro,\n",
    "    t_CStoP_pro,\n",
    ")\n",
    "print (f\"CtoSP prediction:\\n\")\n",
    "print (\n",
    "    colored(t_CtoSP_out[:input_len_for_tasks['CtoSP']], 'blue')+\\\n",
    "    colored(t_CtoSP_out[input_len_for_tasks['CtoSP']:], 'red'),\n",
    ")\n",
    "print ()\n",
    "print (f\"CStoP prediction:\\n\")\n",
    "print (\n",
    "    colored(t_CStoP_out[:input_len_for_tasks['CStoP']], 'blue')+\\\n",
    "    colored(t_CStoP_out[input_len_for_tasks['CStoP']:], 'red'),\n",
    ")\n",
    "print ()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd88aa9-cc6f-4260-a644-458e69b5fd90",
   "metadata": {},
   "source": [
    "### Inverse deisgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0a7b755-e050-4d9c-b0a6-ce9c07fbef46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this demo, we focus on P-to-SC designs...\n",
      "\n",
      "Pick 10th record from the test set...\n",
      "\n",
      "The input prompt is \n",
      "\u001b[34m{Task:Gene001}={Property:[DiffusionResistivity:+8.984e-01,Misfit:+1.037e+00,CoarseningMetric:+1.155e+00,FreezingRange:+2.343e-01,CrackSusceptibilityCoefficient:+1.860e-01,HotCrackingSusceptibility:+4.357e-02]}=>{Structure:[\u001b[0m\n",
      "\n",
      "We apply AlloyGPT to complete the sentence twice...\n",
      "\n",
      "1st generation:\n",
      "\n",
      "\u001b[34m{Task:Gene001}={Property:[DiffusionResistivity:+8.984e-01,Misfit:+1.037e+00,CoarseningMetric:+1.155e+00,FreezingRange:+2.343e-01,CrackSusceptibilityCoefficient:+1.860e-01,HotCrackingSusceptibility:+4.357e-02]}=>{Structure:[\u001b[0m\u001b[31mAsBuilt_L12Mol%:+1.220e+01,AsBuilt_TernaryMol%:+4.965e+00,AsBuilt_Al3NiMol%:+0.000e+00,AsBuilt_Al3ZrMol%:+1.667e-02,L12Mol%:+1.471e+01,TernaryMol%:+0.000e+00,Al3NiMol%:+3.881e+00,Al3ZrMol%:+0.000e+00]}=>{Composition:[(Al):+9.564e+01,(Ni):+9.726e-01,(Er):+1.956e+00,(Zr):+1.079e+00,(Y):+3.318e-01,(Yb):+1.182e-01]}\u001b[0m\n",
      "\n",
      "2nd generation:\n",
      "\n",
      "\u001b[34m{Task:Gene001}={Property:[DiffusionResistivity:+8.984e-01,Misfit:+1.037e+00,CoarseningMetric:+1.155e+00,FreezingRange:+2.343e-01,CrackSusceptibilityCoefficient:+1.860e-01,HotCrackingSusceptibility:+4.357e-02]}=>{Structure:[\u001b[0m\u001b[31mAsBuilt_L12Mol%:+6.318e+00,AsBuilt_TernaryMol%:+8.351e+00,AsBuilt_Al3NiMol%:+3.847e+00,AsBuilt_Al3ZrMol%:+1.348e+00,L12Mol%:+1.138e+01,TernaryMol%:+0.000e+00,Al3NiMol%:+1.032e+01,Al3ZrMol%:+0.000e+00]}=>{Composition:[(Al):+9.457e+01,(Ni):+2.581e+00,(Er):+1.377e+00,(Zr):+8.017e-01,(Y):+3.589e-01,(Yb):+2.281e-01]}\u001b[0m\n",
      "\n",
      "Compare the two designs with the ground truth...\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note that, you will need Thermo-Calc to check the design accuracy.\n"
     ]
    }
   ],
   "source": [
    "# print (len(sentence_dataset_dict_sepe['test']['Gene001_sentence']))\n",
    "print (f\"In this demo, we focus on P-to-SC designs...\\n\")\n",
    "\n",
    "i_pick = 10\n",
    "print (f\"Pick {i_pick}th record from the test set...\\n\")\n",
    "\n",
    "# t_full_rec, t_PtoSC_pro = \\\n",
    "# pick_one_and_prepare_promps_Design_PtoSC(\n",
    "#     ii=i_pick\n",
    "# )\n",
    "t_full_rec = sentence_dataset_dict_sepe['test']['Gene001_sentence'][i_pick]\n",
    "t_PtoSC_pro = t_full_rec[:input_len_for_tasks['PtoSC']]\n",
    "\n",
    "print (f\"The input prompt is \\n{colored(t_PtoSC_pro, 'blue')}\\n\")\n",
    "\n",
    "print (f\"We apply AlloyGPT to complete the sentence twice...\\n\")\n",
    "t_PtoSC_out_1, t_PtoSC_out_2 = \\\n",
    "pred_PtoSC_for_one_rec_twice(\n",
    "    t_PtoSC_pro,\n",
    "    pred_t=1.0\n",
    ")\n",
    "\n",
    "print (f\"1st generation:\\n\")\n",
    "print (\n",
    "    colored(t_PtoSC_out_1[:input_len_for_tasks['PtoSC']], 'blue')+\\\n",
    "    colored(t_PtoSC_out_1[input_len_for_tasks['PtoSC']:], 'red'),\n",
    ")\n",
    "print ()\n",
    "print (f\"2nd generation:\\n\")\n",
    "print (\n",
    "    colored(t_PtoSC_out_2[:input_len_for_tasks['PtoSC']], 'blue')+\\\n",
    "    colored(t_PtoSC_out_2[input_len_for_tasks['PtoSC']:], 'red'),\n",
    ")\n",
    "print ()\n",
    "\n",
    "print (f\"Compare the two designs with the ground truth...\\n\")\n",
    "# \n",
    "t_pic = plot_comp_for_PtoSC_1_2_and_FR(\n",
    "    gt=t_full_rec,\n",
    "    PtoSC_out_1=t_PtoSC_out_1,\n",
    "    PtoSC_out_2=t_PtoSC_out_2,\n",
    "    # \n",
    "    file_name=TestKeys['demo_dir']+'/L1_PtoSC_1_2_FR.png'\n",
    ")\n",
    "\n",
    "# Read the PNG image file\n",
    "image = img.imread(TestKeys['demo_dir']+'/L1_PtoSC_1_2_FR.png')\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image)\n",
    "plt.gca().set_axis_off()\n",
    "plt.show()\n",
    "# print (t_full_rec, '\\n\\n', t_PtoSC_pro)\n",
    "plt.close()\n",
    "\n",
    "print (f\"Note that, you will need Thermo-Calc to check the design accuracy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7bd802-beff-4bc8-b280-ff75548a8502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9855f8c2-77b0-446d-92d9-807c112113f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbccda5-354d-47e1-8382-6df3897a0cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cd5efd-68f3-45cb-b3bb-ff04b021259c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0437f648-8760-4d1d-a00f-3c3579b29aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fa0cfe-f8c4-491b-bafc-451a23c55fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a59d2c-9048-444a-9891-7e31870affab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcb0196-becc-4374-bf14-b6dcc9ad4bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AlloyGPT_env)",
   "language": "python",
   "name": "alloygpt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
